{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aff424bc",
   "metadata": {},
   "source": [
    "# Chapter 5: Resampling Methods\n",
    "\n",
    "Resampling methods are an indispensable tool in modern statistics. They involve repeatedly drawing samples from a training set and refitting a model of interest on each sample in order to obtain additional information about the fitted model.  Two of the most commonly used resampling methods are cross-validation and bootstrap. \n",
    "\n",
    "- Cross-validation can be used to estimate the test error associated with a given statistical learning method in order to evaluate its performance, or to select the appropriate level of flexibility. The process of evaluating a model’s performance is known as model assessment, whereas the process of selecting the proper level of flexibility for a model is known as model selection. \n",
    "\n",
    "- Bootstrap is used in several contexts, most commonly to provide a measure of accuracy of a parameter estimate or of a given statistical learning method.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee179497",
   "metadata": {},
   "source": [
    "# 5.1. Cross Validation\n",
    "\n",
    "In general, the training error rate often is quite different from the test error rate, and in particular the former can dramatically underestimate the latter.\n",
    "\n",
    "In the absence of a very large designated test set that can be used to directly estimate the test error rate, a number of techniques can be used to estimate this quantity using the available training data. Some methods make a mathematical adjustment to the training error rate in order to estimate the test error rate.\n",
    "\n",
    "In this section, we instead consider a class of methods that estimate the test error rate by holding out a subset of the training observations from the fitting process, and then applying the statistical learning method to those held out observations. For simplicity we assume that we are interested in performing regression with a quantitative response. Next, we consider the case of classification with a qualitative response."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea891e3",
   "metadata": {},
   "source": [
    "# The (single) validation set approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4600dbac",
   "metadata": {},
   "source": [
    "\n",
    "We begin by using the sample() function to split the set of observations sample() into two halves, by selecting a random subset of 196 observations out of\n",
    "the original 392 observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f2309b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(ISLR2)\n",
    "attach(Auto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fa896ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>392</li><li>9</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 392\n",
       "\\item 9\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 392\n",
       "2. 9\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 392   9"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dim(Auto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fd146d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 6 × 9</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>mpg</th><th scope=col>cylinders</th><th scope=col>displacement</th><th scope=col>horsepower</th><th scope=col>weight</th><th scope=col>acceleration</th><th scope=col>year</th><th scope=col>origin</th><th scope=col>name</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;fct&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>18</td><td>8</td><td>307</td><td>130</td><td>3504</td><td>12.0</td><td>70</td><td>1</td><td>chevrolet chevelle malibu</td></tr>\n",
       "\t<tr><th scope=row>2</th><td>15</td><td>8</td><td>350</td><td>165</td><td>3693</td><td>11.5</td><td>70</td><td>1</td><td>buick skylark 320        </td></tr>\n",
       "\t<tr><th scope=row>3</th><td>18</td><td>8</td><td>318</td><td>150</td><td>3436</td><td>11.0</td><td>70</td><td>1</td><td>plymouth satellite       </td></tr>\n",
       "\t<tr><th scope=row>4</th><td>16</td><td>8</td><td>304</td><td>150</td><td>3433</td><td>12.0</td><td>70</td><td>1</td><td>amc rebel sst            </td></tr>\n",
       "\t<tr><th scope=row>5</th><td>17</td><td>8</td><td>302</td><td>140</td><td>3449</td><td>10.5</td><td>70</td><td>1</td><td>ford torino              </td></tr>\n",
       "\t<tr><th scope=row>6</th><td>15</td><td>8</td><td>429</td><td>198</td><td>4341</td><td>10.0</td><td>70</td><td>1</td><td>ford galaxie 500         </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 × 9\n",
       "\\begin{tabular}{r|lllllllll}\n",
       "  & mpg & cylinders & displacement & horsepower & weight & acceleration & year & origin & name\\\\\n",
       "  & <dbl> & <int> & <dbl> & <int> & <int> & <dbl> & <int> & <int> & <fct>\\\\\n",
       "\\hline\n",
       "\t1 & 18 & 8 & 307 & 130 & 3504 & 12.0 & 70 & 1 & chevrolet chevelle malibu\\\\\n",
       "\t2 & 15 & 8 & 350 & 165 & 3693 & 11.5 & 70 & 1 & buick skylark 320        \\\\\n",
       "\t3 & 18 & 8 & 318 & 150 & 3436 & 11.0 & 70 & 1 & plymouth satellite       \\\\\n",
       "\t4 & 16 & 8 & 304 & 150 & 3433 & 12.0 & 70 & 1 & amc rebel sst            \\\\\n",
       "\t5 & 17 & 8 & 302 & 140 & 3449 & 10.5 & 70 & 1 & ford torino              \\\\\n",
       "\t6 & 15 & 8 & 429 & 198 & 4341 & 10.0 & 70 & 1 & ford galaxie 500         \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 × 9\n",
       "\n",
       "| <!--/--> | mpg &lt;dbl&gt; | cylinders &lt;int&gt; | displacement &lt;dbl&gt; | horsepower &lt;int&gt; | weight &lt;int&gt; | acceleration &lt;dbl&gt; | year &lt;int&gt; | origin &lt;int&gt; | name &lt;fct&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|---|\n",
       "| 1 | 18 | 8 | 307 | 130 | 3504 | 12.0 | 70 | 1 | chevrolet chevelle malibu |\n",
       "| 2 | 15 | 8 | 350 | 165 | 3693 | 11.5 | 70 | 1 | buick skylark 320         |\n",
       "| 3 | 18 | 8 | 318 | 150 | 3436 | 11.0 | 70 | 1 | plymouth satellite        |\n",
       "| 4 | 16 | 8 | 304 | 150 | 3433 | 12.0 | 70 | 1 | amc rebel sst             |\n",
       "| 5 | 17 | 8 | 302 | 140 | 3449 | 10.5 | 70 | 1 | ford torino               |\n",
       "| 6 | 15 | 8 | 429 | 198 | 4341 | 10.0 | 70 | 1 | ford galaxie 500          |\n",
       "\n"
      ],
      "text/plain": [
       "  mpg cylinders displacement horsepower weight acceleration year origin\n",
       "1 18  8         307          130        3504   12.0         70   1     \n",
       "2 15  8         350          165        3693   11.5         70   1     \n",
       "3 18  8         318          150        3436   11.0         70   1     \n",
       "4 16  8         304          150        3433   12.0         70   1     \n",
       "5 17  8         302          140        3449   10.5         70   1     \n",
       "6 15  8         429          198        4341   10.0         70   1     \n",
       "  name                     \n",
       "1 chevrolet chevelle malibu\n",
       "2 buick skylark 320        \n",
       "3 plymouth satellite       \n",
       "4 amc rebel sst            \n",
       "5 ford torino              \n",
       "6 ford galaxie 500         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(Auto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4c8b6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FIRST CHOICE OF VALIDATION SET: 196 RANDOM SAMPLES\n",
    "set.seed(1)\n",
    "train <- sample(392, 196)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13d6541d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "23.2660086465003"
      ],
      "text/latex": [
       "23.2660086465003"
      ],
      "text/markdown": [
       "23.2660086465003"
      ],
      "text/plain": [
       "[1] 23.26601"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Linear regression\n",
    "lm_fit <- lm(mpg ~ horsepower, subset = train)\n",
    "#calculate the error on the validation set\n",
    "#Note that the -train index below selects only the observations \n",
    "#that are not in the training set\n",
    "mean((mpg - predict(lm_fit, Auto))[-train]^2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a42a4a15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "18.7164594933828"
      ],
      "text/latex": [
       "18.7164594933828"
      ],
      "text/markdown": [
       "18.7164594933828"
      ],
      "text/plain": [
       "[1] 18.71646"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Quadratic regression\n",
    "lm_fit2 <- lm(mpg ~ poly(horsepower,2), subset = train)\n",
    "mean((mpg - predict(lm_fit2, Auto))[-train]^2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c47e000",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "18.7940067973945"
      ],
      "text/latex": [
       "18.7940067973945"
      ],
      "text/markdown": [
       "18.7940067973945"
      ],
      "text/plain": [
       "[1] 18.79401"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Cubic regression\n",
    "lm_fit3 <- lm(mpg ~ poly(horsepower,3), subset = train)\n",
    "mean((mpg - predict(lm_fit3, Auto))[-train]^2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4d6f31",
   "metadata": {},
   "source": [
    "The estimated test MSE for the linear regression fit is 23.27. For the quadratic and cubic regressions, the error rates are 18.72 and 18.79, respectively. Quadratic model seems a better fit than both linear and cubic models.  If we choose a different training set instead, then we will obtain somewhat different errors on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ede227c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SECOND CHOICE OF VALIDATION SET: ANOTHER 196 RANDOM SAMPLES\n",
    "set.seed(2)\n",
    "train2 <- sample(392, 196)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71026f78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "25.7265106448139"
      ],
      "text/latex": [
       "25.7265106448139"
      ],
      "text/markdown": [
       "25.7265106448139"
      ],
      "text/plain": [
       "[1] 25.72651"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "20.4303642741463"
      ],
      "text/latex": [
       "20.4303642741463"
      ],
      "text/markdown": [
       "20.4303642741463"
      ],
      "text/plain": [
       "[1] 20.43036"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "20.3853268638776"
      ],
      "text/latex": [
       "20.3853268638776"
      ],
      "text/markdown": [
       "20.3853268638776"
      ],
      "text/plain": [
       "[1] 20.38533"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Linear regression\n",
    "lm_fit <- lm(mpg ~ horsepower, subset = train2)\n",
    "mean((mpg - predict(lm_fit, Auto))[-train2]^2)\n",
    "\n",
    "#Quadratic regression\n",
    "lm_fit2 <- lm(mpg ~ poly(horsepower,2), subset = train2)\n",
    "mean((mpg - predict(lm_fit2, Auto))[-train2]^2)\n",
    "\n",
    "#Cubic regression\n",
    "lm_fit3 <- lm(mpg ~ poly(horsepower,3), subset = train2)\n",
    "mean((mpg - predict(lm_fit3, Auto))[-train2]^2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2593b8de",
   "metadata": {},
   "source": [
    "Using the second validation set, the quadratic model still does better than the linear model, but is slightly worse than the cubic. \n",
    "\n",
    "Here are the findings from the using the 2 different validation sets above:  a model that predicts *mpg* using a quadratic function of *horsepower* performs better than a model that involves only a linear function of *horsepower*, and there is little evidence in favor of a model that uses a cubic function of *horsepower*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177aeaed",
   "metadata": {},
   "source": [
    "# Leave-One-Out Cross Validation (LOOCV)\n",
    "\n",
    "Like the validation set approach, LOOCV involves splitting the set of observations into two parts. \n",
    "- However, instead of creating two subsets of comparable size, a single observation $(x_1,y_1)$ is used for the validation set, and the remaining observations ${(x_2, y_2), \\ldots , (x_n, y_n)}$ make up the training set. The statistical learning method is fit on the $n − 1$ training observations, and a prediction $\\hat{y}_1$ is made for the excluded observation using its value $x_1$. Since $(x_1, y_1)$ was not used in the fitting process, $MSE_1 = (y_1 − \\hat{y}_1)^2$ provides an approximately unbiased estimate for the test error. But even though $MSE_1$ is unbiased for the test error, it is a poor estimate because it is highly variable, since it is based upon a single observation $(x_1, y_1)$.\n",
    "\n",
    "- We can repeat the procedure by selecting $(x_2,y_2)$ for the validation data, training the statistical learning procedure on the $n − 1$ observations ${(x_1,y_1),(x_3,y_3), \\ldots,(x_n,y_n)}$,and computing $MSE_2 =(y_2−\\hat{y}_2)^2$. \n",
    "\n",
    "- Repeating this approach n times produces n squared errors, $MSE_1, \\ldots, MSE_n$. The LOOCV estimate for the test MSE is the average of these n test error estimates:\n",
    "\n",
    "    - $CV_n = \\frac{1}{n}\\sum_{i=1}^n MSE_i$\n",
    "    \n",
    "- LOOCV has a couple of major advantages over the validation set approach. First, it has far less bias. In LOOCV, we repeatedly fit the statistical learning method using training sets that contain $n − 1$ observations, almost as many as are in the entire data set. This is in contrast to the validation set approach, in which the training set is typically around half the size of the original data set. \n",
    "  - Consequently, the LOOCV approach tends not to overestimate the test error rate as much as the validation set approach does.\n",
    "  - Second, in contrast to the validation approach which will yield different results when applied repeatedly due to randomness in the training/validation set splits, performing LOOCV multiple times will always yield the same results: there is no randomness in the training/vali- dation set splits.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3956f94",
   "metadata": {},
   "source": [
    "The LOOCV estimate can be automatically computed for any generalized linear model using the *glm()* and *cv.glm()* functions. The *glm()* function can be used to perform logistic regression by passing in the *family = \"binomial\"* argument. Here, we will perform linear regression using the *glm()* function rather than the *lm()* function because the former can be used together with *cv.glm()*. The *cv.glm()* function is part of the *boot* library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c57226c",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(boot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ef29946",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "$call\n",
       "cv.glm(data = Auto, glmfit = glm_fit)\n",
       "\n",
       "$K\n",
       "[1] 392\n",
       "\n",
       "$delta\n",
       "[1] 24.23151 24.23114\n",
       "\n",
       "$seed\n",
       "  [1]       10403         292   241038711  -724551010  -982165160 -1828904773\n",
       "  [7]  1219649113   639708648  -249104362 -1532738671  -205493181  1178813266\n",
       " [13]   334776292   619230759  -943223171   845950836   574669658  1135228325\n",
       " [19]  1324937663  -225314234  -259712816  1901458163   760603665  1517777472\n",
       " [25]  -353409506   333918441  1007243803  1823191594 -1096755892  2047555343\n",
       " [31]    36174405 -1271550980  -709741998  1365872589   667289991 -2093876114\n",
       " [37]  2061812808  1112530507  -120106071  -226796808   147205670   833570625\n",
       " [43]   791874771 -1221193598   282619572  -321910217 -1307274963  1192534596\n",
       " [49]  -516456598 -1233040427 -1928163985  1129724022  1863340960  -338181021\n",
       " [55]  -448311039  -256091024 -2016258034  -559437703  1778395147 -1105262278\n",
       " [61]   166402108   -19181697   426083541  1074993388  1545622082  1292039581\n",
       " [67]  1261006871  -194927234  -601294024 -1892334565 -1536975495 -1797657656\n",
       " [73]   -38799370  1610275377   239717475  -604261326  -536620668   845797319\n",
       " [79]  1754618525  1214392852 -1429288774   586749189 -1730887969   587875174\n",
       " [85]  -904748304   672121363   -54498383  1480726112  1623135230  2031094665\n",
       " [91] -2039817029 -1814243190 -1606497428 -1824984849 -1596875995  -880638500\n",
       " [97]  1951458226  1469794989  1610621543 -1477541490  -315013528 -1967721877\n",
       "[103] -2085860343   156693144   965051846  -932641503  1197057459 -1633947358\n",
       "[109]  -309015788 -1219595369 -1463256179  -785873244  -421959542 -1062695179\n",
       "[115]  -336916145   999251542 -2076424960  -262791101  -952249375   860711760\n",
       "[121]  2101607854   166400857 -1620321941   225362138  1630562716 -1517587041\n",
       "[127] -1274951691   265766540 -1931087006  1167170365 -2085811273   503398494\n",
       "[133]   -65790568   909314299 -1730128743   268399912   374625238 -1757951919\n",
       "[139]   892390147  1181977234   493131812 -1682069785 -1504339139  -947600460\n",
       "[145] -1030189030  1675588453   678678015 -1797865338  1334660112 -1283674445\n",
       "[151]   -82739887 -1505405696  1111932894   941079593  1318247387  -609132310\n",
       "[157]  -295719284   245051855  2080408965   976559676  1455584018   875057165\n",
       "[163]   361124679  1824041262  1956921480  2124596619   950263145  -417919176\n",
       "[169]  -157584922  -269556351  2084387091   677148354  -586485388  1869613431\n",
       "[175]  2130049645 -1030736636  1083969578  1863962005  1177604655  -313319626\n",
       "[181] -1012932768  1623303587 -1291219263  -269605200  -973897266   402289977\n",
       "[187]  -327653045 -1236116742    83024892 -1227580353  1307051285  2097704492\n",
       "[193]  -281709822   880299997  -911979817  1624294846  -472252424   804961243\n",
       "[199]  1277638201    77242248 -1010671818   347512177  -745572445 -1174651150\n",
       "[205]    79554116   920340743   883691741  -303516204  2077157626  1905365061\n",
       "[211]  1215936671  -766516698  1646868144 -1075389613  1488991857 -1584825440\n",
       "[217]   914451262 -1652559287     7775995 -1859905846  1414457388  -512053201\n",
       "[223]   528011493  -855590500  1758151666   496778861  -785667161  1294308814\n",
       "[229] -1863417048   488125074  1278490912 -2038677044   921281248   404484290\n",
       "[235]  -613405656 -1412032596    58366652  -322515982  -909986256  1505804196\n",
       "[241] -1465512520 -1523693734  -152006512  1641118588  -527245036  1018198338\n",
       "[247]  1470021888 -1891758660  -166731440   816011554 -1071916472 -1884475380\n",
       "[253] -2141170084   628476370  -304482816  -209914540  -973247256  1433092346\n",
       "[259]  1704011472   -88847572 -1111912204   681318802  1950203232  1995049996\n",
       "[265]  -352142112   -19226014  1800340648  1068629068 -1146415236  1722620210\n",
       "[271]  1051349616  1499976516  2096690136  -908721286 -1870100432  -223252548\n",
       "[277]  1837474388  -791064510 -1980305760   503440060   278547408  -799040158\n",
       "[283]  2049662696 -2098938676  1559892476   401391090  1461519488  1215711732\n",
       "[289]  2117753480   465652538 -1788670640  1581624428 -2084002412   107348050\n",
       "[295]  1291615712   -15092532  1774034592 -1379708542  1626781928 -1372914964\n",
       "[301] -1229085380    50352242  2115818096 -1332639196 -1541728200  1949935898\n",
       "[307]  -485931824 -1600845508  -836607084  -115148926  -951219264  -802585028\n",
       "[313] -1778278000  -800122846 -1441028856  1886967948 -2133061860 -1466141550\n",
       "[319]  1088673152 -1591570412  1709315880  -265951686  1774973392   992754028\n",
       "[325] -1771736140   741460498  1272719328 -2073695796  1350154464  -360575966\n",
       "[331] -1020734680  1430329868   607814460  1439473650   673624816  -930342332\n",
       "[337]  1721134680 -1136879814   754839536 -2048417092   711103764 -1422336830\n",
       "[343]  -635491232  -752929412  1842204624 -2112134878  -476981592  1306720140\n",
       "[349] -1199999812 -1488123086 -1770289600   217404596  1421263944 -1870264902\n",
       "[355]  -247698928 -1869415188   -97091244  -761236718  -930673248  -915866932\n",
       "[361] -1155319200 -2141052990  -546098392  1085725100   282357052  2101099378\n",
       "[367]  -730301136   517703460  1361823032 -1078728998  1901264784 -1379681540\n",
       "[373] -2101163116  1778623554  1593718016   909891644  2056453456 -1631849310\n",
       "[379]  1674128200  1630019340    -7569700   630968146  1113634432  -245606316\n",
       "[385] -1759632408  2041191162  -267942576  1396895532 -1593138316   862483346\n",
       "[391]  -796917152   551139212  -490440864  1238053858  1840294824 -1928217396\n",
       "[397]   828193276   503416754  -811133456 -2080655932 -1172813480  2016959866\n",
       "[403]   282688944   356578236  -350773164  1927860162   484069408  -897625924\n",
       "[409]  -432780720  -370182174  1213849192  -131133876 -2103951108 -1286535182\n",
       "[415]   316466432  1723224948  1535381512  1866535354  -937316912 -1812925460\n",
       "[421] -1613583468  -679760942 -1050605728 -1433263796 -1674153696  2139692930\n",
       "[427] -1178417432 -1716832020  -449440196  -935341198   693573232  1537647652\n",
       "[433]  -499056840  1750759578  1745100496  1747000508 -1303573868   611275394\n",
       "[439]  1763614912   665081148  1698478224   258487842  1096725000   471317772\n",
       "[445]   497767068   845497874  1964198272  1857821204  1164103208  1354232122\n",
       "[451]   461208528  1656421996  -439921868  -557509998 -1897257632  -600040116\n",
       "[457]  -788043687   153732555  1152550460  2143549546 -1726037345 -1350267095\n",
       "[463]    99627966  1641251500   444559357  -898730169 -1201080272 -1805233842\n",
       "[469]  2073958779  -188195107 -1063397622 -2143556056  -371460463  1663524483\n",
       "[475]   326623108 -1673095758 -1525679353  -951078575    92702934 -1575262796\n",
       "[481] -1370611259  -357486321  1650880392  -917750106  -250007981   850890677\n",
       "[487]  1246248210 -1337481504  -487523511  1169806715 -1484193716  -663021094\n",
       "[493]   752178127   534494617 -2029419090  -978464068 -1231899859   915857623\n",
       "[499] -1606686432  1166208638  1194301515  -943635891    73769082   681193656\n",
       "[505]   242958945 -1190053869 -1052223948    54140994    19505239  1918653345\n",
       "[511]  2074563686  1421040740 -1478502507  2128543935 -1616027560  1233806454\n",
       "[517] -2003129213 -1024410427  -711730718 -1301151664 -1379204743   642848427\n",
       "[523]     9289244  1925110090   553294143  1206542217   107249566 -1927418292\n",
       "[529] -1263929315  1676601767   709094608 -1387123090  -259393253 -1302553987\n",
       "[535]  1696768106 -1661039352  1636743601 -1212994013   421227300 -2059002926\n",
       "[541]   106965031 -1893965199   -89880394  -787140524  1144164581  1036324079\n",
       "[547]  1925177384  1886950534     3415731   327819285 -1308331406  -996761920\n",
       "[553]  -924749015  1136206235  1037579884   118159994  1472371631 -1674445127\n",
       "[559]  -800886578  2145069596   -22077043  1983901687  1351316224   667928926\n",
       "[565]  1819814443   815064365  2087254426  1974450008   914243265  -439017101\n",
       "[571]  1855908500   103198498  1531525687 -1325183231   -30284282  -501318588\n",
       "[577]  1454079349 -1147617057 -2050407368  1378542614  1350960163  -553557019\n",
       "[583]   600647170  -123696016   912235033 -2131741685   527537916  -313086166\n",
       "[589]   325968223  -362366743    -5971970    98743276 -1054574787  -746165497\n",
       "[595] -1541627152   503097998   241034427  1541255325   505019466 -1256266136\n",
       "[601] -1532392879   283654467 -1648799676   212181746  1583844039   795519121\n",
       "[607]  -933546474 -1945971596  -838709499   203685199   181985096  -671140122\n",
       "[613] -1744881645 -1734942859 -1303097518  -427317344  -744529271 -1641019717\n",
       "[619] -1042348788 -1183692646 -1561760241   707701337   898156270   626447740\n",
       "[625] -1844980243  1367433108\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "glm_fit <- glm(mpg ~ horsepower)\n",
    "cv_err <- cv.glm(Auto, glm_fit)\n",
    "cv_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "904f02b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>24.2315135179292</li><li>24.2311440937562</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 24.2315135179292\n",
       "\\item 24.2311440937562\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 24.2315135179292\n",
       "2. 24.2311440937562\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 24.23151 24.23114"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cv_err$delta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea6aede",
   "metadata": {},
   "source": [
    " The *cv.glm()* function produces a list with several components. The two numbers in the delta vector contain the cross-validation results. In this case the numbers are identical (up to two decimal places) and correspond to the LOOCV statistic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ab16b8",
   "metadata": {},
   "source": [
    "## LOOCV for polynomial fits up to order 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c112dd1",
   "metadata": {},
   "source": [
    "We can repeat this procedure for increasingly complex polynomial fits.\n",
    "To automate the process, we use the *for()* function to initiate a for loop *for()*\n",
    "which iteratively fits polynomial regressions for polynomials of order *i = 1* to *i = 10*, computes the associated cross-validation error, and stores it in the ith element of the vector *cv_error*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f030ea97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#intialize the cv_err vector\n",
    "cv_err <- rep(0,10)\n",
    "#loop\n",
    "for(i in 1:10){\n",
    "    glm_fit <- glm(mpg ~ poly(horsepower,i))\n",
    "    cv_err[i] <- cv.glm(Auto, glm_fit)$delta[1]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "860f9968",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>24.2315135179292</li><li>19.2482131244897</li><li>19.3349840640291</li><li>19.4244303104303</li><li>19.0332138547041</li><li>18.9786436582254</li><li>18.8330450653182</li><li>18.9611507120531</li><li>19.0686299814598</li><li>19.4909322993313</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 24.2315135179292\n",
       "\\item 19.2482131244897\n",
       "\\item 19.3349840640291\n",
       "\\item 19.4244303104303\n",
       "\\item 19.0332138547041\n",
       "\\item 18.9786436582254\n",
       "\\item 18.8330450653182\n",
       "\\item 18.9611507120531\n",
       "\\item 19.0686299814598\n",
       "\\item 19.4909322993313\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 24.2315135179292\n",
       "2. 19.2482131244897\n",
       "3. 19.3349840640291\n",
       "4. 19.4244303104303\n",
       "5. 19.0332138547041\n",
       "6. 18.9786436582254\n",
       "7. 18.8330450653182\n",
       "8. 18.9611507120531\n",
       "9. 19.0686299814598\n",
       "10. 19.4909322993313\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] 24.23151 19.24821 19.33498 19.42443 19.03321 18.97864 18.83305 18.96115\n",
       " [9] 19.06863 19.49093"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cv_err"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87c1a63",
   "metadata": {},
   "source": [
    "We see a sharp drop in the estimated test MSE between the linear and quadratic fits, but then no clear improvement from using higher-order polynomials."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c53282f",
   "metadata": {},
   "source": [
    "# k-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94eca2b7",
   "metadata": {},
   "source": [
    "An alternative to LOOCV is $k$-fold CV. This approach involves randomly dividing the set of observations into $k$ groups, or folds, of approximately equal size. The first fold is treated as a validation set, and the method is fit on the remaining $k - 1$ folds. The mean squared error, $MSE_1$, is then computed on the observations in the held-out fold. This procedure is repeated k times; each time, a different group of observations is treated as a validation set. This process results in $k$ estimates of the test error, $MSE_1, MSE_2, \\ldots, MSE_k$. The $k$-fold CV estimate is computed by averaging these values,\n",
    "\n",
    "- $CV_k = \\frac{1}{k}\\sum^k_{i=1}MSE_i$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f3d48ce0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>24.2720671232254</li><li>19.2690928085129</li><li>19.3480535605547</li><li>19.2949648229745</li><li>19.0319790002896</li><li>18.89781210564</li><li>19.1206066690695</li><li>19.1466631054789</li><li>18.8701307442149</li><li>20.9552042280376</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 24.2720671232254\n",
       "\\item 19.2690928085129\n",
       "\\item 19.3480535605547\n",
       "\\item 19.2949648229745\n",
       "\\item 19.0319790002896\n",
       "\\item 18.89781210564\n",
       "\\item 19.1206066690695\n",
       "\\item 19.1466631054789\n",
       "\\item 18.8701307442149\n",
       "\\item 20.9552042280376\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 24.2720671232254\n",
       "2. 19.2690928085129\n",
       "3. 19.3480535605547\n",
       "4. 19.2949648229745\n",
       "5. 19.0319790002896\n",
       "6. 18.89781210564\n",
       "7. 19.1206066690695\n",
       "8. 19.1466631054789\n",
       "9. 18.8701307442149\n",
       "10. 20.9552042280376\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] 24.27207 19.26909 19.34805 19.29496 19.03198 18.89781 19.12061 19.14666\n",
       " [9] 18.87013 20.95520"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set.seed(17)\n",
    "cv_err_10 <- rep(0,10)\n",
    "for(i in 1:10){\n",
    "    glm_fit <- glm(mpg ~ poly(horsepower, i))\n",
    "    cv_err_10[i] <- cv.glm(Auto, glm_fit, K = 10)$delta[1]\n",
    "}\n",
    "cv_err_10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6aa99e",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "Chapter 5, **An Introduction to Statistical Learning\n",
    "with Applications in R**, Gareth James, Daniela Witten, Trevor Hastie and Robert Tibshirani"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
